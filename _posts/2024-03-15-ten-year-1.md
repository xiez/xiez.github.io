# 一名 Web 开发者过去12年学到的东西 - 工具、技术和思考方式（第一部分）

不知不觉，从事软件开发工作至今已经12年了，在行业里摸爬滚打的这些年里，或多或少学到了一些技能，另外对于软件开发这行也有一些粗浅的经验。本文总结了我学到的一些技能以及工具，在下一篇博文里再聊下自己的随想以及软件工程相关的经验。

软件工程的本质是控制复杂度，控制复杂度的方式之一就是选择合适的工具来解决特定的问题，所以一个人工具箱里装的工具越多，同时对工具的适用场景也越熟悉，他解决问题的效率也就越高。所幸的是，对于web开发来说，并不需要的太多的工具。下图展示了我作为一个典型的 Web 开发者工具箱里的工具，主要分为3大类：后端，DevOps 以及前端。

![skill tree](../../assets/images/2024/03/skill-tree.png "skill tree")


## 后端

Web 后端开发技术又可以分为编程语言，Web 框架，中间件和数据库这4类。

### 编程语言

#### Python

过去这些年里，Python 作为我的主力开发语言，占据了差不多 80% 的工作时间，包括了服务端应用，命令行脚本，甚至于 PC 端应用。

这门语言的特点很显著，简洁的语法外加完善的第三方类库，使得开发效率非常高，适合快速原型以及小规模系统的开发。至于经常被人诟病的运行速度慢的问题，对于以“请求-响应”为主的 Web 应用来说，其实并不算问题，毕竟大部分的时间开销都花在了等待数据库以及其他中间系统上。在少量一些性能关键的地方，还可以使用 C 扩展来优化，像 [Pandas](https://github.com/pandas-dev/pandas) 项目就是 90% 的 Python 代码外加 6% 左右的 Cython 代码。

当然，作为一门动态语言，由于没有编译器做额外的检查，很容易出现运行时错误，这一点在多人参与的项目里会被进一步放大。所以，在我参与或主导的项目里，都会引入代码静态检查（pep8,flakes,mypy等）外加自动化单元测试来保证系统的稳定。

此外，Python 2 和 3 版本的不兼容导致的社区分裂，在我看来才是这门语言的最大问题。我并不是说两者的语法有大的差异，我使用 Python 2.7 超过 7 年的时间，用了不到一周时间就可以流畅的使用 Python 3 开发项目。Python 2 的官方支持结束时间是 2020 年 1 月 1 日，四年之后的 2024 年，我依然会有差不多 20% 的时间需要花在这上面。这类项目大部分都是公司里的“祖传”项目，开发、测试、产品人员换了一波又一波，几十万行的代码逻辑像年久失修的管道一样纵横交错，而在商业上，这类项目每年还能给公司带来几百上千万的收入，所以不管从个人还是公司层面，都没有动力去迁移代码。长此以往，越来越多的安全漏洞被暴露出来，系统就会变得异常脆弱，直接或间接损害经济利益。可以预见的是，不管是国内外，运行着 Python 2 的遗留系统还会一直存在，一直到软件生命周期的终点。

#### 其他

除了 Python，剩下 20% 的时间里，我基本在 Node.js，Go，Bash，Clojure 等各类语言间切换。对于稍微有点规模的公司来说，内部必然有各种技术栈，难免会参与或接手这类项目。我也表达下自己对这几类语言的看法。

Node.js 项目最多，大约占据了我一半的时间。毕竟任何一个前端开发，只要稍微学下后端的开发框架，再熟悉下数据库的操作基本就可以成为“全栈开发”。从我个人有限的使用来说，开发体验只能说一般。水平参差不齐的第三方库在选择上需要费不少功夫，另外，纯异步的语法（虽然有 async/await 的加持）有时候也让人头痛。所以，就我个人而言，并没有什么特别好的理由在项目里使用它。当然，Node.js 作者 Ryan Dahl 的[这番话也对我有所影响](https://mappingthejourney.com/single-post/2017/08/31/episode-8-interview-with-ryan-dahl-creator-of-nodejs/)。

> [...] if you’re building a server, I can’t imagine using anything other than Go. [...] I think Node is not the best system to build a massive server web. I would use Go for that. And honestly, that’s the reason why I left Node. It was the realization that: oh, actually, this is not the best server-side system ever.

> [...] 如果你正在构建一个服务器，我简直无法想象会使用除了Go以外的任何东西。[...] 我认为 Node 不是构建大规模服务器端 Web 应用的最佳系统。对于这个任务，我会选择 Go。而且说实话，这就是我离开 Node 的原因。我意识到：哦，其实这并不是有史以来最好的服务器端系统。

Go 语言过去十年在国内一直处于比较火的状态，布道者很多，大大小小的公司也都在用。我个人也一直在关注，看了不少相关文章以及对核心团队的采访视频，不过一直到去年才真正有机会参与到相关的项目里。针对外界宣传的语言简洁，我倒没有太大的认同，可能跟我一直写 Python 有关，静态语言由于有类型系统的存在，简洁性上肯定无法与动态语言相比。当然，相对于 C/C++/Java，确实语法上简洁不少，毕竟是 09 年才发布的新语言，吸收了不少现代语言的优点。此外，标榜的运行速度的优势，作为一款静态编译型语言，肯定要比 Python 之类的动态解释型语言要快一个数量级不止。但由于有 GC 的存在，速度上必然也比不上 C/C++ 之类的无 GC 语言。这门语言在我看来最突出的两个特点：

- 它是第一门解决了[函数颜色问题](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)的生产级别的语言。大部分的语言在处理异步上都选择函数库（例如 Python 的 asyncio），这样就会导致项目里存在同步和异步两套代码，同步代码无法调用异步代码，除非把自己也变成异步；异步代码虽然可以调用同步代码，但会阻塞事件循环。而 Go 选择在语言的 Runtime 层面上来解决这个问题，这在根源上消除了同步和异步代码的区别，在我看来是唯一正确的处理方式。这也是为什么很多人觉得用 Go 写并发代码很方便。当然，这一切都归功于 Rob Pike 这位并发理论大师。

- 语言层面就强制统一代码风格。大部分语言都有各自推荐的代码风格，但真正写起来，每个人又有各自习惯的风格，缩进使用 tab 还是 space？左括号放在行末还是另起一行？种种问题导致的争论，持续了半个多世纪。在 Google 这种汇集了全世界最优秀的几万人的大厂里，这种争吵带来的间接经济损失肯定是巨大的。Go 语言的作者 Robert Griesemer 显然是看到了这一点，直接在语言层面强制统一风格，从此，世界就安静了。所以就连上古大神 Ken Tompson 也[称赞了这一设计](https://www.youtube.com/watch?v=sln-gJaURzk&t=2722s)。

说到 Ken Tompson, 作为 Go 语言的三位核心作者之一，在[采访中](https://www.reddit.com/r/golang/comments/6ou8fm/why_ken_thompson_was_enthusiastic_about_go/)说到自己在读到 C++ 0x的提案标准后，下定决心转向 Go。老爷子的话里可能有点调侃的意思，但这也说明了 Go 语言最初的目标是在公司内部取代一部分过去只能用 C++ 写的项目。所以，在我看来，Go 也可以称做 C++- 或者 C+，它简化了 C++ 功能特性，增强了 C 语言的部分特性。

总的来说，如果仅仅用来做中小规模、几十万代码量级别的 Web 常规应用，我更倾向于 Python。因为如果使用 Go，代码量会膨胀到百万级别，开发和维护成本都会直线上升。至于 Python 性能上的问题，只要能通过增加机器来解决，基本上都不是问题，毕竟人比机器要贵的多。而在涉及网络、并发、性能等中间件领域，大量的网络连接使得传统的线程占用了太多的资源，而事件循环又无法利用到多核，所以，使用 Go 就非常合适，例如，分布式kv数据库 Etcd，web 服务器 Caddy，容器编排平台 K8S 等。

Bash 作为曾今的“胶水语言”，在项目里使用的频率越来越少了，我也就偶尔维护下前人留下来的脚本而已。就我个人而言，这门语言永远记不住的怪异语法，费力的调试过程都让人头大。所以，但凡10分钟内无法搞定的功能，我会改用 Python 来实现。

Clojure 在国内应该算是小众语言，基本没什么公司在用，我也只是在一些业余项目里使用，这门语言接下来几年我还会继续深入。有几点原因使我选择这门语言：

- 它是一门生产级别的 Lisp。在看完 [SICP](https://github.com/xiez/SICP-exercises) 后，我很想找一门 Lisp 在项目里用用，可选的范围有：Common Lisp, Clojure, Racket 以及 Emacs Lisp。Clojure 排名最靠前，因为它跑在 JVM 里，可以用到 Java 生态的组件。

- 它的异步库 `core.async` 借鉴了 Go 的并发思想，也使用了 CSP 并发范式，包含了 channel, coroutine 等概念，我可以对比两者的差异，从而对 Go 的并发模型有更深的理解。

- [Jepson](https://jepsen.io/analyses) 里有大量的 Clojure 例子代码，简洁很具有表达力，但如果不了解这门语言，不容易读懂那些评测文章。

Java，由于我仅仅在刚参加工作时使用了半年多时间，基本上无法评判，[据说](https://www.yinwang.org/blog-cn/2016/01/18/java)除了语法比较繁琐，其他各方面都比较均衡。我个人更喜欢一眼就可以看到完整逻辑的代码，如果为了所谓的代码扩展性考虑，把逻辑分拆到几个甚至十几个文件里，我看到就会很头痛，毕竟大部分项目都只是业务逻辑的实现，不需要像框架一样灵活。

C++ 和 Rust，由于我一直没机会使用，所以也无法评判。我只知道 Rust 起源于 Mozilla, 单单一个 Firefox，C/C++ 代码量就在[千万级别](https://4e6.github.io/firefox-lang-stats/)，在这种超大规模的项目里，引入更高层次抽象的新语言，解决内存安全、性能瓶颈等问题，非常合理。然而，这几年掀起了 Rust 取代 C++ 的风潮，似乎万物皆可 Rust，我比较持怀疑态度，毕竟大部分公司项目的复杂度相比浏览器来说，还是简单不少。此外，取代 C++ 的风潮从 90 年代开始一直没停歇过，从 Java 到 Go 再到 Rust，到了 2024 年，在 [tiobe](https://www.tiobe.com/tiobe-index/) 排行榜上 C++ 第3，Java 第4，Rust 位列第18。Rust 究竟能否取代 C++，再过十年也许能看出点迹象吧。

### Web 框架

#### Django

Django 作为我入门时的框架，从 1.4 版本一直用到 1.11，差不多有十年，总的来说，这是一个对新人很友好的框架。特别是官方文档，包含了 Web 开发的方方面面，从入门介绍教程，再到ORM、模版渲染、网络安全、国际化、性能优化、部署方案等等。工作中遇到的问题基本都可以从文档本身或者文中给出的外部资料找到解决方案。总的来说，这是一个成熟可靠、功能全面的框架。所以，不管是个人项目还是公司项目，Django 都会是我的首选方案。

#### 其他

自从 21 年换到新公司后，我基本都在使用“轻量级”框架，Flask 和 Tornado，也短暂用过 Fastapi, Express 以及 Gin，这些框架不管是文档，还是系统成熟度上都跟 Django 有所差距。

Flask 这几年很多公司在用，主打一个轻便、灵活，经常用来作为内部的微服务项目。它的插件式设计思路，允许开发者灵活的根据需要选择相应的组件，与 Django 大而全的思路刚好相反。这比较考验开发者的能力，所以在我看来，Flask 对于初学者来说不如 Django 友好。所以，如果团队里大部分都是普通水准的开发人员，需要有一两个“资深开发”负责选型。

Tornado 作为支持协程的异步框架，起初这类框架的出现是为了解决经典的 C10K 问题，后来被人们总结为性能好、速度快。当然，这仅仅只能在各种测试环境下，实际情况并非如此。因为我们都很难拒绝同步代码的诱惑，不管是因为项目交期的压力，或者是没有可供选择的异步库，所以，大部分这类项目都更容易出现卡顿等性能问题。我参与的很多项目里，由于没有好的异步 ORM 组件，或者受限于开发人员的能力，很多系统在运行一段时间后频繁出现卡顿。我曾花了好几天时间，才在几十万行的代码里定位到，某个极少用到的边缘功能，由于使用了同步数据库查询操作导致了整个系统无法使用。

Fastapi 最为更现代的异步框架，受限于 Python 异步模型的问题，依旧存在上述问题，所以在我看来，它的使用场景也很有限。

总的来说，就框架选型而言，对于大部分的 Web 项目，同步框架应该是优先选择的，至于是 Django 还是 Flask，取决于公司的技术栈以及对应的开发人员水平。而异步框架，只有在服务器客户端双向通信、服务端下发事件等需要维持长时间连接的场景下才需要考虑。

### 中间件

#### 缓存

在我刚工作的头几年，Memcached 作为缓存系统被广泛使用。后来随着 Redis 的普及，人们发现 Redis 除了能提供 key-value 的缓存功能外，还提供了丰富的数据结构用来做实时分析、排行榜、队列等，此外，Redis 还支持持久化。所以，Redis 成为了大部分公司缓存系统的首选。而 Memcached 只有在小众情况下才会被使用，例如团队成员过去有丰富的经验，而且业务场景里仅仅只有缓存单一需求。

#### 消息系统

在 Web 系统里，“请求-响应”能满足大部分的瞬时需求，但无法满足小部分的耗时操作。例如，等待第三方系统返回结果，这过程可能需要几小时或几天。所以，我们一般会引入异步通信来解耦，也就是消息队列。我用过常见的有几种：

- Redis 队列和 Pub/Sub 机制能用来实现简单的消息队列功能，在有些场景下（例如，私有部署 self-hosting 项目），不想引入过多的额外系统，比较适用。

- RabbitMQ 作为最常见的消息系统被广泛使用，它提供了消息队列、持久化、集群部署、管理监控界面，而且，它可靠、灵活度高，基本上是我的首选方案。

- Kafka 可以用来做消息队列，事实上很多公司把它当作 RabbitMQ 的替代来使用，这在我看来是有问题的。正如[这篇文章](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)所介绍的，Kafka 的定位是日志文件，它的最大价值在于解耦了公司内部各系统间的数据流，把系统间通信的复杂度从 O(N*N) 降到了 O(N)。从抽象上来说，每一个 topic 都是一个文件，并且这个文件是分布式、可扩展的。事实上，它在分布式系统里的用途等同于 Binlog/WAL 在数据库里的作用。

![kafka](../../assets/images/2024/03/kafka.png "kafka")


总的来说，Kafka 的应用更加广泛，但在某些场景下（例如延迟队列）Kafka 不能很好的满足，与其用起来磕磕绊绊，不如选择 RabbitMQ 等专业的消息系统。


### 数据库

数据库作为持久化组件，任何一个 Web 项目都会用到。根据我的使用场景，分为两大类：

#### 关系型

- SQLite 作为内嵌型数据库，主要用于桌面软件以及私有化部署项目，在这些场景下不方便引入额外的数据库组件，所以使用这种轻量级、零配置的数据库引擎。大部分的企业级项目基本上不会用它，会选择更专业的数据库。当然，并不是说 SQLite 不够专业，相反，这是一个经过验证的、生产级别的数据库，只要你有足够的经验和强劲的机器，[400万的QPS](https://use.expensify.com/blog/scaling-sqlite-to-4m-qps-on-a-single-server)也不在话下。所以，就我个人而言，个人项目我优先会使用这个。

- MySQL 作为老牌的关系型数据库，得益于 LAMP 架构，在国内外的流行度很高，国内大部分的公司都会使用，网上也有大量的教程和问题总结。多年用下来没遇到什么问题，只是低版本缺少 JSON 字段的支持，用起来不怎么方便。

- PostgreSQL 作为严格遵循 SQL 标准的数据库，在国外很流行，[2023 SO 开发者问卷调查](https://survey.stackoverflow.co/2023/#technology)流行度超过 MySQL，位列第一。我也用过两年多，对我来说，它对于 JSON 字段的支持以及全文搜索的能力，免去了引入 mongodb 以及 es 等非关系性数据库，降低了系统的整体复杂度，很符合我当时的业务场景。[hacknews](https://news.ycombinator.com/item?id=33934139) 上也有关于用 postgres 替代 redis/mq/es 等组件的讨论，这种 all-in-postgres 的理念，对于特定场景还是很有吸引力的，它不但简化了部署架构，也免去了 ETL 造成数据不一致的问题。

#### 文档型

- MongoDB 作为文档型数据库，在国内外一度很流行。就我个人两年多的使用来看，它的定位更像是关系性数据库的物料视图，灵活的表结构，非常便于项目的迭代。当然，如果使用不当，很容易造成项目无法维护。过去一年多，我接手的几个 Python 遗留项目里，由于没有使用 ORM 框架，导致字段的缺失，一个字段存储不同类型的数据等等问题都让人头痛，项目的稳定性和迭代速度也因此受到影响。所以，使用 Mongo 这类 schema-free 或者更准确说是 schema-on-read 的数据系统时，需要配合类型系统（例如，ORM 或者静态语言的类型定义）做一定的约束，这样项目在长期迭代过程中才能保持稳定。

- ElasticSearch 作为另一种文档型数据库，大部分场景下用来做全文搜索。使用看下来，唯一需要注意的点就是有时候系统资源占用会比较大。另外，更新索引的组件如果没有足够的监控，容易导致搜索结果异常。

这些年，关系型和文档型数据库之间的界限也逐渐模糊，Postgres 对于 JSON 文档的支持[更加完善](https://www.postgresql.org/docs/current/datatype-json.html)，而 MongoDB 也声称支持了完整的 ACID 事务，不过[评测机构似乎不这么认为](https://jepsen.io/analyses/mongodb-4.2.6)：

> MongoDB’s claim of “full ACID transactions” which “maintain the same data integrity guarantees you are used to in traditional databases” could be misleading. We recommend that users who are accustomed to serializable behavior evaluate critical transactions carefully, to identify whether running at snapshot isolation could violate application-level constraints. MongoDB may wish to revise their marketing language to use “snapshot isolated” instead of “ACID”.

> MongoDB声称他们提供了“完全符合ACID要求的事务”，并且能够“保持传统数据库中您所熟悉的数据完整性保证”，但这有可能会误导人。我们建议那些习惯于串行操作的用户要仔细评估关键的事务，以确定在使用快照隔离模式时是否会违反应用程序层面的限制。或许 MongoDB 需要修改他们的营销用语，用“快照隔离”来取代“ACID”。

所以，总的来说，对于常见的 Web 应用场景，关系型数据库应该是我的首选，因为大部分的读写并发场景都需要事务来保证数据的完整性。文档型数据库作为补充，主要用来优化应用整体的读取性能。

## DevOps

DevOps 这一理念的出发点是为了增加后端开发和运维人员的协作和沟通，从而提高软件的交付速度和质量。就我个人来说，熟悉这方面的工具能使我的工作效率更高。

### 操作系统

- Linux 作为绝大多数应用的服务端系统，对于大部分人来说并不需要掌握太底层的原理，日常用到的基本就是安装/卸载软件，查看系统资源、日志等常规操作。但就我观察下来，能够熟练使用的开发人员并没有很多。Linux 桌面非常适合开发人员使用，但办公和娱乐应用方面的支持较少，所以我后来基本都转向了 Mac 系统。

- MacOS 作为开发系统，我已经用了超过10年，大部分的时间里，我都在终端 iTerm，编辑器 Emacs 以及几个浏览器里工作。作为桌面系统，它比 Windows 稳定，我可以连续一年多不关机，系统依旧运行流畅，仅开关机一项每年能为我节省几千分钟的时间，更别说 Win 系统里时不时的弹出广告对于工作思路的中断，而且虚拟机也能替代一部分需要 Windows 的场景。

### 云计算

- AWS 作为云计算领域常年的 No 1，云主机 EC2，对象存储 S3 以及数据库 RDS 用下来都非常安全可靠，唯一可能需要诟病的就是管理后台使用体验上有点不方便。除此之外，不管面向国内还是国外客户，AWS 一直都会是我的首选。

- GCP 作为谷歌的云计算产品，由于总所周知的原因，国内基本没多少公司在用。我主要用来做一些实验性质的项目，例如搭建 K8S 集群，部署开源 LLM 等。

### 云原生

- Docker 作为容器时代的代表产品，它解决了应用程序及其依赖环境隔离这一普遍性的问题。在此之前，各个语言有各自的解决方案，Python 的 virtualenv 和 pyenv，Node.js 的 nvm，Go 的 gvm 等，这些工具在一定程度上可以实现环境隔离，但它们通常是针对特定语言或开发环境。Docker 的出现改变了这种情况，它提供了镜像这一统一且低成本的解决方案。自从 2018 年接触后，Docker 已经成为我日常高频次使用的工具之一。不管是大大小小的项目，我都会优先构建开发环境的 DockerFile，一方面可以熟悉项目的部署，更重要的是有了 DockerFile，任何人都可以一键构建出一摸一样的开发环境。团队内共享一个开发环境可以有效避免环境依赖问题导致的 bug。除此之外，Docker 在生产环境的应用也节省了运维人员大量的时间，减少了出错的可能性，提高了系统稳定性。所以，我大胆预测下，下一个十年，尽管 Docker 可能会被其他的竞品赶超，例如 Podman，但容器化的理念依旧会发挥重要作用。

- K8s & Rancher 作为云原生技术栈中两个重要的组件，很多公司都会一起使用。K8s 作为容器编排和管理平台，给企业提供了高可用性、弹性和可扩展性等一系列公有云才有的优势，而且作为更高一层的抽象，K8s 可以对接各类公有云厂商，有效解决了 Vendor lock-in 这个公有云最大的问题，使企业可以根据需要选择合适的公有云或者本地部署。另外，它对于运维实施人员成本的降低，对公司机器利用率的提高等都对企业有着很大的吸引力。Rancher 更多时候作为 K8s 的管理界面，在使用体验上要优于 K8s 自带的界面。当然，K8s 的缺点也很明显，系统里有太多的 moving parts（不可控因素）以及过多的抽象，使得学习成本较高，出了问题，也需要花更多的时间排查。所以，总的来说，我个人更倾向于在集成和测试环境引入，给团队足够的熟悉时间，逐步扩散到非关键的生产环境，最后到所有生产环境，这个周期在几个月到几年不等。

### CI / CD

- GitlabCI & Jenkins 是国内用的最广泛的本地部署的 CI 工具，也是为数不多的使用 Bash 脚本的地方。就我个人而言，GitlabCI 的使用体验上要由于 Jenkins，毕竟 Yaml 语法要比 Groovy 简单不少。

- ArgoCD 作为依托于 K8s 的持续部署工具，也是 GitOps 理念的实践者。我个人很喜欢这个理念，把运维部署也纳入到 Git 的版本管理里，提高了运维的自动化、可重复和可审计，通过 diff 就能直观的看到每次的部署变更，回滚也只需要 git revert 就行。我个人[实践过大半年](../gitops-in-practice/)，效果显著，以后如果有机会我还会继续尝试。

总的来说，作为现代的后端开发人员，具备 DevOps 相关的技能是非常有益的，不仅可以方便自己的工作，也能为团队和他人带来便利。在科技行业大裁员以及降本增效的时代背景下，DevOps 这一理念应该会越来越重要。

## 前端

作为后端开发，熟悉一些前端领域的工具能培养开发者端到端开发的能力以及系统性思维，从而提高工作效率，这也是“全栈开发”理念的由来。在这些年的工作中，我使用的工具如下：

- Chrome 浏览器作为新时代的 IE，基本上占据了开发人员以及普通用户的桌面。作为以后端开发为主的开发人员，Chrome 开发者工具也是我日常使用的高频工具之一。从查看网络请求和响应，到检查控制台输出以及应用 Cookie 等等，这些都是排查问题的首要步骤，用来快速定位问题所在。

- Javascript 作为浏览器端的唯一语言，这几年也吸收了不少其他语言的优点，例如 ES6 的解构赋值、模版字符串、箭头函数，ES8 的 async/await 等等这些改进都提升了开发者的使用体验。而 TS 的出现也让大规模应用开发变得容易（虽然，我个人更喜欢[类型注解](https://stateful.com/blog/type-annotations-javascript)这种方式）。另外，纯异步的编程模型也让习惯了同步代码的人开阔了思维。当然，JS 最让人诟病的就是依赖库的膨胀问题，随便一个项目都有几百上千的依赖库，深不见底的 node_modules 对项目的维护升级和安全性造成了不小困扰。所以，就我个人而言，我会尽量手动实现或者找寻更轻量级的包。

- jQuery 作为曾今最流行的类库，简便的 DOM 操作很大程度上缓减了写 JS 的痛苦。现如今有了更现代的工具，实体 DOM 的操作频率不像以前那么高了，jQuery 的使用率也在降低，但在一些遗留项目或特定场景下，它依旧是一种有价值的工具。

- React.js 作为虚拟 DOM 的推动者，给前端开发带来了变革。在此之前，开发者需要同时关注界面和数据状态，React 的界面自动渲染，抽象成了 `view=func(state)`，开发者只需要关注数据的变化，而不用直接操作 DOM，降低了开发门槛。另外，React 也让前端开始变得对后端开发友好，毕竟，对于数据状态的处理是后端开发的强项。事实上，在我 2018 年首次接触时，React 里的组件化开发、声明式模型、纯函数组件等理念都让我感到亲切，一两个礼拜时间就能做出不错的功能。

总的来说，前端开发也在朝工程化的方向发展，模块化组件、自动化构建工具等都有助于提高开发效率和可维护性，以应对日益复杂的应用需求。

---

终于写完了，一不小心写多了，以上就是我这些年里工具的使用心得，工具不算多，但要把工具用好还是需要花费不少功夫。我始终认为，了解技术或工具的创造背景可以帮助我们更好地理解其设计原理、用途和适用范围，从而提高工作效率。选对了工具，就像网球击中球拍的“甜点区”一样，舒适而又省力。

下一个十年，最重要的工具无疑就是 AI 了，过去一年多，ChatGPT 在我每天工作中的使用占比已经超过了 Google + StackOverflow。从 GPT 到 Facebook 的 Llama 2 再到 Google 的 Gemini，这些语言和多模态模型正在重塑各个行业，软件开发也不例外。正如 DDH [前几天博文里所总结的](https://world.hey.com/dhh/developers-are-on-edge-4dfcf9c1?utm_source=pocket_saves)，在技术进步的长期趋势下，没有任何职业能够完全抵制自动化或冗余。正如农业行业的总体价值自工业化前时代以来大幅增长，即使从业人数的占比大量减少。可以预见的是，在不远的将来，能够适应技术发展变化的“码农们”在自动化工具的加持下，工作效率会得到10倍甚至百倍的提升，而那些无法适应的将逐渐被淘汰出行业，或者只能在一些偏远落后的组织里做着手动重复的低效工作。

在第二部分里，我会聊下软件工程的经验，AI 的看法和使用心得以及其他各种随想。所以，stay tuned～
